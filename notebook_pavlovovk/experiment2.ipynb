{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/cleaned/South_East_Asia_Social_Media_MentalHealth_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[['Daily SM Usage (hrs)', 'Peer Comparison Frequency (1-10)', 'Cyberbullying Experience (1-10)']]\n",
    "y = data_df['Self Confidence Impact (1-10)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09907016308811452\n",
      "[[704 674 622 691 704 712 731 698 679 673]\n",
      " [686 697 676 633 702 661 666 731 669 725]\n",
      " [652 694 659 711 706 682 707 671 714 695]\n",
      " [676 713 682 672 661 643 661 659 746 633]\n",
      " [714 715 724 728 687 649 657 705 673 684]\n",
      " [686 721 658 693 664 646 705 681 638 700]\n",
      " [675 701 657 647 701 692 693 693 687 636]\n",
      " [635 719 647 703 700 674 706 675 714 670]\n",
      " [715 669 617 681 689 658 661 675 642 674]\n",
      " [666 692 669 652 675 673 678 689 705 680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.10      0.10      6888\n",
      "           2       0.10      0.10      0.10      6846\n",
      "           3       0.10      0.10      0.10      6891\n",
      "           4       0.10      0.10      0.10      6746\n",
      "           5       0.10      0.10      0.10      6936\n",
      "           6       0.10      0.10      0.10      6792\n",
      "           7       0.10      0.10      0.10      6782\n",
      "           8       0.10      0.10      0.10      6843\n",
      "           9       0.09      0.10      0.09      6681\n",
      "          10       0.10      0.10      0.10      6779\n",
      "\n",
      "    accuracy                           0.10     68184\n",
      "   macro avg       0.10      0.10      0.10     68184\n",
      "weighted avg       0.10      0.10      0.10     68184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09939281942977825\n",
      "[[  27    0    0  168    5    0 4412 2237    0   39]\n",
      " [  32    0    0  167    4    0 4404 2208    0   31]\n",
      " [  26    0    0  150    2    0 4510 2162    0   41]\n",
      " [  40    0    0  183    2    0 4385 2104    0   32]\n",
      " [  36    0    0  174    8    0 4482 2201    0   35]\n",
      " [  32    0    0  167    4    0 4384 2181    0   24]\n",
      " [  25    0    0  160    3    0 4384 2179    0   31]\n",
      " [  35    0    0  166    5    0 4452 2140    0   45]\n",
      " [  31    0    0  143    5    0 4371 2086    0   45]\n",
      " [  26    0    0  170    4    0 4445 2099    0   35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.00      0.01      6888\n",
      "           2       0.00      0.00      0.00      6846\n",
      "           3       0.00      0.00      0.00      6891\n",
      "           4       0.11      0.03      0.04      6746\n",
      "           5       0.19      0.00      0.00      6936\n",
      "           6       0.00      0.00      0.00      6792\n",
      "           7       0.10      0.65      0.17      6782\n",
      "           8       0.10      0.31      0.15      6843\n",
      "           9       0.00      0.00      0.00      6681\n",
      "          10       0.10      0.01      0.01      6779\n",
      "\n",
      "    accuracy                           0.10     68184\n",
      "   macro avg       0.07      0.10      0.04     68184\n",
      "weighted avg       0.07      0.10      0.04     68184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
